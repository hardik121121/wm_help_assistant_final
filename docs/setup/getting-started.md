# Getting Started - Watermelon Documentation Assistant

**Welcome!** This guide explains the project in simple terms for anyone seeing this codebase for the first time.

## âœ… Production Status (Nov 7, 2025)

**ğŸ‰ The system is PRODUCTION READY!**

- âœ… **78% Precision** - 78% of top-10 results are relevant
- âœ… **100% MRR** - First result is ALWAYS relevant
- âœ… **92.7% Quality Score** - Outstanding answer quality
- âœ… **100% Success Rate** - No failures on complex queries
- âœ… **25.2s avg response time** - Fast and efficient
- âœ… **$0.003 per query** - Cost-effective

---

## What Does This Project Do?

This is an **AI-powered documentation assistant** that answers complex questions about Watermelon's help documentation (2,257 pages).

**Example Question**: *"How do I create a no-code block on Watermelon and set up MS Teams integration?"*

**What Makes It Special**:
- **AI-Enhanced Chunks**: 2,133 chunks with AI-generated topics, summaries, and semantic classification
- **Multi-Topic Understanding**: Breaks complex questions into sub-questions
- **Hybrid Search**: Combines semantic similarity and keyword matching
- **Comprehensive Answers**: Step-by-step instructions with 1,549 semantically-named images
- **Perfect First-Result Accuracy**: MRR = 100% (first result always relevant)

---

## Project Overview

### The Problem We're Solving

Traditional documentation search fails when:
- Questions span multiple topics (e.g., "create a block" + "test it")
- Exact keywords don't match documentation wording
- Users need step-by-step instructions combining multiple sections
- Images and visual guides are important

### Our Solution: Advanced RAG System

**RAG** = Retrieval-Augmented Generation (fancy term for "find relevant info, then generate answer")

**Our approach**:
1. Break complex questions into smaller sub-questions
2. Find relevant documentation sections using smart search
3. Combine information from multiple sections
4. Generate comprehensive answers with citations and images

---

## How It Works (Simple Explanation)

```
User Question: "How do I set up MS Teams integration?"
    â†“
Step 1: Understand the Question
    - Break into sub-questions if complex
    - Identify question type (how-to, troubleshooting, etc.)
    â†“
Step 2: Find Relevant Information
    - Search 2,106 documentation chunks
    - Use both meaning-based search (AI embeddings) + keyword search
    - Rank results by relevance
    â†“
Step 3: Generate Answer
    - Combine information from top results
    - Create step-by-step instructions
    - Include images and citations
    â†“
Step 4: Validate Quality
    - Check completeness and formatting
    - Ensure answer addresses the question
    â†“
Final Answer: Detailed MS Teams setup guide with images
```

---

## System Architecture

**ğŸ“– For comprehensive architecture documentation, see [Technical Architecture Guide](../technical/architecture.md)**

This includes:
- Complete system architecture with all layers
- Detailed strategies and innovations (query expansion, context chaining, etc.)
- Full tech stack breakdown
- Complete folder/file structure with descriptions
- Data flow diagrams
- Design patterns and decisions
- Performance characteristics

### High-Level Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           USER INTERFACE                             â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Streamlit Web App (app.py)                                  â”‚  â”‚
â”‚  â”‚  - Query input                                               â”‚  â”‚
â”‚  â”‚  - Answer display with images                                â”‚  â”‚
â”‚  â”‚  - Pipeline metrics & visualization                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    END-TO-END PIPELINE                               â”‚
â”‚                   (end_to_end_pipeline.py)                          â”‚
â”‚                                                                      â”‚
â”‚  Orchestrates all 4 stages of the RAG pipeline                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“                          â†“                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   STAGE 1:      â”‚    â”‚   STAGE 2:          â”‚    â”‚   STAGE 3:          â”‚
â”‚   QUERY         â”‚ â†’  â”‚   MULTI-STEP        â”‚ â†’  â”‚   ANSWER            â”‚
â”‚   UNDERSTANDING â”‚    â”‚   RETRIEVAL         â”‚    â”‚   GENERATION        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                          â†“                            â†“
         â†“                          â†“                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“                          â†“                   â”‚   STAGE 4:      â”‚
         â†“                          â†“                   â”‚   VALIDATION    â”‚
         â†“                          â†“                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                          â†“
         â†“              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“              â†“                       â†“
         â†“     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“     â”‚  HYBRID SEARCH  â”‚    â”‚   RERANKING     â”‚
         â†“     â”‚  (Vector+BM25)  â”‚    â”‚   (Cohere)      â”‚
         â†“     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“              â†“                       â†“
         â†“              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                          â†“
         â†“              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“              â”‚  CONTEXT ORGANIZER  â”‚
         â†“              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA STORAGE LAYER                              â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   Pinecone     â”‚  â”‚   BM25 Index   â”‚  â”‚  Embeddings    â”‚       â”‚
â”‚  â”‚  (Cloud DB)    â”‚  â”‚   (Local)      â”‚  â”‚    (Local)     â”‚       â”‚
â”‚  â”‚                â”‚  â”‚                â”‚  â”‚                â”‚       â”‚
â”‚  â”‚ 2,106 vectors  â”‚  â”‚ 16,460 terms   â”‚  â”‚ Content maps   â”‚       â”‚
â”‚  â”‚ 3072-dim       â”‚  â”‚                â”‚  â”‚ Metadata maps  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘                          â†‘                       â†‘
         â”‚                          â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCUMENT PROCESSING                               â”‚
â”‚                    (Offline - One-time setup)                       â”‚
â”‚                                                                      â”‚
â”‚  PDF (2,257 pages) â†’ Docling â†’ Hierarchical Chunker â†’ Embeddings   â”‚
â”‚                                                                      â”‚
â”‚  Output: 2,106 chunks with full metadata + images                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Architecture (Detailed)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STAGE 1: QUERY UNDERSTANDING                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  User Query â†’ Query Understanding Pipeline                          â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 1. Query Decomposer (LLM-based)                              â”‚  â”‚
â”‚  â”‚    - Breaks complex queries into sub-questions                â”‚  â”‚
â”‚  â”‚    - Uses Groq Llama 3.3 70B                                 â”‚  â”‚
â”‚  â”‚    - Example: "Create block + test it" â†’ 2 sub-questions    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 2. Query Classifier (Rule-based)                             â”‚  â”‚
â”‚  â”‚    - Identifies question type (procedural, conceptual, etc.) â”‚  â”‚
â”‚  â”‚    - Detects complexity level                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 3. Intent Analyzer                                            â”‚  â”‚
â”‚  â”‚    - Extracts user intent                                     â”‚  â”‚
â”‚  â”‚    - Determines generation strategy                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  Output: QueryUnderstanding object with sub-questions + metadata    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STAGE 2: MULTI-STEP RETRIEVAL                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  For EACH Sub-Question:                                             â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 1. Generate Query Embedding                                   â”‚  â”‚
â”‚  â”‚    - OpenAI text-embedding-3-large                           â”‚  â”‚
â”‚  â”‚    - 3072 dimensions                                         â”‚  â”‚
â”‚  â”‚    - Cost: ~$0.0001 per embedding                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 2. Hybrid Search                                              â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚    â”‚  Vector Search      â”‚  â”‚  BM25 Search       â”‚          â”‚  â”‚
â”‚  â”‚    â”‚  (Pinecone)         â”‚  â”‚  (Local Index)     â”‚          â”‚  â”‚
â”‚  â”‚    â”‚  - Semantic match   â”‚  â”‚  - Keyword match   â”‚          â”‚  â”‚
â”‚  â”‚    â”‚  - Top 30 results   â”‚  â”‚  - Top 30 results  â”‚          â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â”‚               â†“                        â†“                      â”‚  â”‚
â”‚  â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚  â”‚
â”‚  â”‚                            â†“                                  â”‚  â”‚
â”‚  â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚  â”‚
â”‚  â”‚                 â”‚   RRF Fusion        â”‚                       â”‚  â”‚
â”‚  â”‚                 â”‚   (50/50 weights)   â”‚                       â”‚  â”‚
â”‚  â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 3. Keyword Boosting (MS Teams Fix!)                          â”‚  â”‚
â”‚  â”‚    - Detect exact integration names                          â”‚  â”‚
â”‚  â”‚    - Apply 10x score boost                                   â”‚  â”‚
â”‚  â”‚    - Skip reranking if exact match found                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 4. Semantic Reranking (if no exact match)                    â”‚  â”‚
â”‚  â”‚    - Cohere rerank-english-v3.0                              â”‚  â”‚
â”‚  â”‚    - Re-scores top 30 results                                â”‚  â”‚
â”‚  â”‚    - Keeps top 10 after reranking                            â”‚  â”‚
â”‚  â”‚    - Cost: ~$0.0005 per rerank                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 5. Context Organization                                       â”‚  â”‚
â”‚  â”‚    - Combine results from all sub-questions                  â”‚  â”‚
â”‚  â”‚    - Deduplicate (keep highest score)                        â”‚  â”‚
â”‚  â”‚    - Sort by: boosted flag â†’ score â†’ section â†’ page         â”‚  â”‚
â”‚  â”‚    - Group by topic for readability                          â”‚  â”‚
â”‚  â”‚    - Keep top 20 chunks for LLM                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  Output: OrganizedContext with 20 ranked chunks + metadata          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STAGE 3: ANSWER GENERATION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 1. Format Context                                             â”‚  â”‚
â”‚  â”‚    - Convert 20 chunks to markdown format                    â”‚  â”‚
â”‚  â”‚    - Preserve ranking order                                  â”‚  â”‚
â”‚  â”‚    - Include section headings and page numbers               â”‚  â”‚
â”‚  â”‚    - Add note: "First sections are most relevant"            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 2. Select Generation Strategy                                 â”‚  â”‚
â”‚  â”‚    - Procedural: Step-by-step instructions                   â”‚  â”‚
â”‚  â”‚    - Comparison: Feature comparison tables                   â”‚  â”‚
â”‚  â”‚    - Troubleshooting: Diagnosis + solutions                  â”‚  â”‚
â”‚  â”‚    - Conceptual: Comprehensive explanation                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 3. Build Prompt                                               â”‚  â”‚
â”‚  â”‚    - Query + formatted context                               â”‚  â”‚
â”‚  â”‚    - Strategy-specific instructions                          â”‚  â”‚
â”‚  â”‚    - Citation requirements                                   â”‚  â”‚
â”‚  â”‚    - Image referencing instructions                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 4. Generate Answer                                            â”‚  â”‚
â”‚  â”‚    - Groq API (Llama 3.3 70B)                                â”‚  â”‚
â”‚  â”‚    - Temperature: 0.3 (focused)                              â”‚  â”‚
â”‚  â”‚    - Max tokens: 2000                                        â”‚  â”‚
â”‚  â”‚    - Cost: FREE (within rate limits)                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 5. Post-Process Answer                                        â”‚  â”‚
â”‚  â”‚    - Extract citations                                       â”‚  â”‚
â”‚  â”‚    - Extract image references                                â”‚  â”‚
â”‚  â”‚    - Calculate confidence score                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  Output: GeneratedAnswer with text + citations + images             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STAGE 4: VALIDATION                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 1. Completeness Check                                         â”‚  â”‚
â”‚  â”‚    - Does answer address all sub-questions?                  â”‚  â”‚
â”‚  â”‚    - Are key points covered?                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 2. Formatting Check                                           â”‚  â”‚
â”‚  â”‚    - Proper markdown structure?                              â”‚  â”‚
â”‚  â”‚    - Step numbers if procedural?                             â”‚  â”‚
â”‚  â”‚    - Citations present?                                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 3. Quality Scoring                                            â”‚  â”‚
â”‚  â”‚    - Overall score (0-1)                                     â”‚  â”‚
â”‚  â”‚    - Completeness score                                      â”‚  â”‚
â”‚  â”‚    - Formatting score                                        â”‚  â”‚
â”‚  â”‚    - Flag issues and warnings                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  Output: ValidationResult with scores + issues                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
                          Final PipelineResult
                    (Answer + Metrics + Validation)
```

### Data Flow Architecture

```
OFFLINE PROCESSING (One-time Setup)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF File  â”‚  157 MB, 2,257 pages
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“ Docling Processing (~15-60 min)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Structured JSON â”‚  43 MB with layout, tables, images
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“ Hierarchical Chunking (~1-2 min)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2,106 Chunks       â”‚  Each chunk includes:
â”‚  + Full Metadata    â”‚  - Content (500-2000 chars)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Section hierarchy
       â”‚                  - Images, tables
       â”‚                  - 20+ metadata fields
       â”‚
       â†“ Parallel Processing
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â†“                  â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embeddings â”‚   â”‚ Pinecone DB â”‚   â”‚  BM25 Index  â”‚
â”‚ Generation â”‚   â”‚   Upload    â”‚   â”‚  Creation    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  (~5 min)          (~2 min)          (<1 min)
  $0.08 total       FREE              FREE
       â”‚                  â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  SEARCH READY!     â”‚
              â”‚  - Vector index    â”‚
              â”‚  - Keyword index   â”‚
              â”‚  - Content maps    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ONLINE QUERY PROCESSING (Per Query)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

User Query
    â†“
Query Understanding (~1-2s, FREE)
    â”œâ”€â”€ Decomposition (LLM)
    â”œâ”€â”€ Classification (Rules)
    â””â”€â”€ Intent Analysis
    â†“
    â”œâ”€ Sub-question 1 â”€â”€â”€â”€â”
    â”œâ”€ Sub-question 2 â”€â”€â”€â”€â”¤ Process in sequence
    â””â”€ Sub-question 3 â”€â”€â”€â”€â”¤ (~3-4s each)
                          â†“
                    For Each Sub-Q:
                          â”‚
                          â”œâ”€ Generate Embedding (~0.3s, $0.0001)
                          â”‚       â†“
                          â”œâ”€ Hybrid Search (~0.5s, FREE)
                          â”‚    â”œâ”€ Vector Search (Pinecone)
                          â”‚    â”œâ”€ BM25 Search (Local)
                          â”‚    â””â”€ RRF Fusion
                          â”‚       â†“
                          â”œâ”€ Keyword Boosting (~0.1s, FREE)
                          â”‚       â†“
                          â”œâ”€ Reranking (~1-2s, $0.0005)
                          â”‚    (Cohere API)
                          â”‚       â†“
                          â””â”€ Results (10 chunks)
                                  â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Context Organization     â”‚
                    â”‚  - Deduplicate            â”‚
                    â”‚  - Aggregate scores       â”‚
                    â”‚  - Sort by relevance      â”‚
                    â”‚  - Keep top 20            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Answer Generation      â”‚
                    â”‚  (~3-4s, FREE)          â”‚
                    â”‚  - Groq Llama 3.3 70B   â”‚
                    â”‚  - Strategy-aware       â”‚
                    â”‚  - Citations            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Validation             â”‚
                    â”‚  (<1s, FREE)            â”‚
                    â”‚  - Quality checks       â”‚
                    â”‚  - Scoring              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                          Final Answer
                    (~27s total, $0.002)
```

### Technology Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Streamlit                  Python web framework                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AI MODELS & APIs                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OpenAI API                 text-embedding-3-large (3072-dim)   â”‚
â”‚  Groq API                   Llama 3.3 70B (generation)          â”‚
â”‚  Cohere API                 rerank-english-v3.0                 â”‚
â”‚  Docling                    PDF processing library              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATABASES                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Pinecone                   Cloud vector database               â”‚
â”‚  Rank-BM25                  Local keyword search                â”‚
â”‚  Pickle                     Local embeddings storage            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PYTHON LIBRARIES                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Pydantic                   Configuration management            â”‚
â”‚  NumPy / SciPy              Mathematical operations             â”‚
â”‚  LangChain                  LLM framework utilities             â”‚
â”‚  BeautifulSoup              HTML/text parsing                   â”‚
â”‚  PIL / Pillow               Image processing                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INFRASTRUCTURE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Python 3.12+               Runtime environment                 â”‚
â”‚  Git                        Version control                     â”‚
â”‚  Virtual Environment        Dependency isolation                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Module Dependencies

```
app.py (Streamlit UI)
    â†“
    â””â”€â†’ src.generation.end_to_end_pipeline
            â†“
            â”œâ”€â†’ src.query.query_understanding
            â”‚       â”œâ”€â†’ src.query.query_decomposer (Groq LLM)
            â”‚       â”œâ”€â†’ src.query.query_classifier (Rules)
            â”‚       â””â”€â†’ src.query.intent_analyzer
            â”‚
            â”œâ”€â†’ src.retrieval.multi_step_retriever
            â”‚       â”œâ”€â†’ src.database.embedding_generator (OpenAI)
            â”‚       â”œâ”€â†’ src.retrieval.hybrid_search
            â”‚       â”‚       â”œâ”€â†’ Pinecone (Cloud API)
            â”‚       â”‚       â””â”€â†’ Rank-BM25 (Local)
            â”‚       â”œâ”€â†’ src.retrieval.reranker (Cohere)
            â”‚       â””â”€â†’ src.retrieval.context_organizer
            â”‚
            â”œâ”€â†’ src.generation.answer_generator (Groq LLM)
            â”‚
            â””â”€â†’ src.generation.response_validator

config.settings (Pydantic)
    â†“
    â””â”€â†’ All modules import settings from here
```

### Critical Architecture Decisions

#### 1. Why Pinecone Instead of Local Vector DB?
- **Pro**: Cloud-hosted, managed, scalable
- **Pro**: Fast similarity search
- **Con**: 40KB metadata limit (solved with content mapping)
- **Alternative**: FAISS (local, but requires more setup)

#### 2. Why Hybrid Search (Vector + BM25)?
- **Vector alone**: Misses exact keyword matches
- **BM25 alone**: Misses semantic similarity
- **Together**: Best of both worlds (0.567 precision)

#### 3. Why Groq Instead of OpenAI for Generation?
- **Pro**: FREE tier (100K tokens/day)
- **Pro**: Fast inference (Llama 3.3 70B)
- **Con**: Rate limits (14 queries/day on free tier)
- **Alternative**: OpenAI GPT-4 (better quality, costs money)

#### 4. Why Cohere Reranking?
- **Pro**: Significantly improves relevance
- **Pro**: Affordable ($0.0005 per query)
- **Con**: API latency (1-2s)
- **Alternative**: Cross-encoder (local, faster, but larger model)

#### 5. Why Hierarchical Chunking?
- **Problem**: Simple chunking loses context
- **Solution**: Include full section hierarchy in every chunk
- **Result**: Better retrieval accuracy

#### 6. Why Content Mapping (MS Teams Fix)?
- **Problem**: Pinecone metadata limit excludes content
- **Solution**: Load content from local embeddings file
- **Result**: Restored full chunk content (1000+ chars)

---

## Project Structure (Where Files Are)

### ğŸ“ Root Directory Files

| File | Purpose | When to Look at It |
|------|---------|-------------------|
| `app.py` | Streamlit web interface | Running the UI, changing display |
| `requirements.txt` | Python dependencies | Setting up environment |
| `.env` | API keys (not in git) | Configuring API access |
| `README.md` | Project overview | Understanding project goals |
| `CLAUDE.md` | AI assistant instructions | Understanding development rules |
| `GETTING_STARTED.md` | This file! | First time setup |

### ğŸ“ `/config` - Configuration Settings

| File | Purpose |
|------|---------|
| `settings.py` | All project settings (paths, model names, parameters) |

**Important**: All configuration is centralized here. Change chunk size, model names, API settings, etc. in one place.

### ğŸ“ `/src/ingestion` - Document Processing

Converts PDF â†’ Structured chunks ready for search

| File | Purpose |
|------|---------|
| `docling_processor.py` | Extracts text, tables, images from PDF |
| `hierarchical_chunker.py` | Splits document into smart chunks with context |
| `chunk_evaluator.py` | Checks chunk quality |

**Output**: `cache/hierarchical_chunks_filtered.json` (2,106 chunks)

### ğŸ“ `/src/database` - Search Indexing

Creates search indexes from chunks

| File | Purpose |
|------|---------|
| `embedding_generator.py` | Converts text to AI embeddings (OpenAI) |
| `vector_store.py` | Manages Pinecone vector database |
| `bm25_index.py` | Creates keyword search index |

**Output**:
- `cache/hierarchical_embeddings.pkl` (AI embeddings)
- `cache/bm25_index.pkl` (Keyword index)
- Pinecone cloud index

### ğŸ“ `/src/query` - Question Understanding

Analyzes user questions before search

| File | Purpose |
|------|---------|
| `query_decomposer.py` | Breaks complex questions into sub-questions |
| `query_classifier.py` | Identifies question type (how-to, troubleshooting, etc.) |
| `intent_analyzer.py` | Extracts user intent |
| `query_understanding.py` | Orchestrates all query analysis |

### ğŸ“ `/src/retrieval` - Smart Search

Finds relevant documentation chunks

| File | Purpose |
|------|---------|
| `hybrid_search.py` | Combines AI search + keyword search |
| `reranker.py` | Re-ranks results for better relevance (Cohere) |
| `context_organizer.py` | Organizes results by topic |
| `multi_step_retriever.py` | Orchestrates full retrieval pipeline |

### ğŸ“ `/src/generation` - Answer Creation

Generates final answers from retrieved context

| File | Purpose |
|------|---------|
| `answer_generator.py` | Generates answers using LLM (Groq Llama 3.3 70B) |
| `response_validator.py` | Validates answer quality |
| `end_to_end_pipeline.py` | Complete pipeline (question â†’ answer) |

### ğŸ“ `/src/evaluation` - Quality Testing

Tests system performance

| File | Purpose |
|------|---------|
| `retrieval_metrics.py` | Measures search quality (Precision, Recall, etc.) |
| `generation_metrics.py` | Measures answer quality |
| `comprehensive_evaluation.py` | Full system evaluation |

### ğŸ“ `/tests` - Test Queries & Results

| File/Folder | Purpose |
|-------------|---------|
| `test_queries.json` | 30 complex test questions |
| `results/` | Evaluation results and metrics |

### ğŸ“ `/cache` - Generated Data Files

| File | Size | Purpose |
|------|------|---------|
| `docling_processed.json` | 43 MB | Structured document after PDF processing |
| `hierarchical_chunks_filtered.json` | 4.5 MB | 2,106 documentation chunks |
| `hierarchical_embeddings.pkl` | 59 MB | AI embeddings for all chunks |
| `bm25_index.pkl` | 64 MB | Keyword search index |
| `images/` | ~200 MB | 1,454 extracted images |

---

## Key Strategies & Techniques

### 1. Hierarchical Chunking

**Problem**: Simple chunking loses context.

**Our Solution**: Every chunk includes full section hierarchy.

**Example**:
```markdown
Section: Getting Started > Integrations > MS Teams

To integrate MS Teams with Watermelon:
1. Navigate to Settings > Integrations
2. Click "Add Integration"
...
```

**Why It Works**: Even if user asks "MS Teams setup," we know it's about integrations, not just a random mention of MS Teams.

### 2. Hybrid Search (Vector + BM25)

**Two types of search combined**:

1. **Vector Search** (AI-based): Finds semantically similar content
   - User: "connect to Teams" â†’ Finds: "MS Teams integration setup"
   - Good for: Understanding meaning, finding synonyms

2. **BM25 Search** (Keyword-based): Finds exact keyword matches
   - User: "MS Teams" â†’ Finds: Documents with "MS Teams"
   - Good for: Exact terms, product names, technical jargon

**Fusion**: Combines both using Reciprocal Rank Fusion (RRF) algorithm

### 3. Multi-Step Retrieval

For complex questions, we:
1. Break question into sub-questions
2. Retrieve for each sub-question separately
3. Combine results intelligently
4. Remove duplicates while preserving ranking

**Example**:
- Question: "How do I create a block and test it?"
- Sub-question 1: "How do I create a block?"
- Sub-question 2: "How do I test a block?"
- Retrieve for both â†’ Combine â†’ Generate unified answer

### 4. Semantic Reranking (Cohere)

After initial search, we use Cohere's reranking model to:
- Re-score results based on semantic relevance
- Promote truly relevant content
- Demote keyword matches that aren't actually relevant

**Exception**: We skip reranking for exact integration name matches to preserve high ranking.

### 5. Keyword Boosting

When user asks about specific integrations (MS Teams, Shopify, etc.):
- Detect exact integration name in query
- Apply 10x score boost to chunks mentioning that integration
- Skip reranking to preserve ranking

**Why**: Prevents reranking model from demoting exact matches.

### 6. Context Organization

Retrieved chunks are organized by:
1. **Boosted chunks first** (exact matches)
2. **Score** (highest relevance)
3. **Topic/section** (grouped by subject)
4. **Page order** (natural document flow)

### 7. Strategy-Aware Generation

LLM adapts answer format based on question type:

| Question Type | Answer Format |
|---------------|---------------|
| How-to (procedural) | Numbered step-by-step instructions |
| Comparison | Structured tables comparing features |
| Troubleshooting | Diagnosis â†’ Solution format |
| Conceptual | Comprehensive explanation |

---

## Common Parameters & Settings

All settings are in `config/settings.py`. Here are the most important ones:

### Document Processing

| Parameter | Value | What It Means |
|-----------|-------|---------------|
| `chunk_size` | 1000 tokens | How many tokens (words) per chunk |
| `chunk_overlap` | 200 tokens | How much chunks overlap to preserve context |
| `min_chunk_size` | 100 tokens | Minimum chunk size (discard smaller) |

**Why These Values**:
- 1000 tokens â‰ˆ 750 words (enough for complete thoughts)
- 200 token overlap prevents cutting sentences in half
- Tested and optimized for this documentation

### Vector Search

| Parameter | Value | What It Means |
|-----------|-------|---------------|
| `embedding_model` | text-embedding-3-large | OpenAI's best embedding model |
| `embedding_dimensions` | 3072 | Vector size (higher = more precise) |
| `vector_top_k` | 30 | How many results from vector search |

**Cost**: ~$0.0005 per query (3 embeddings for sub-questions)

### Keyword Search (BM25)

| Parameter | Value | What It Means |
|-----------|-------|---------------|
| `bm25_top_k` | 30 | How many results from keyword search |
| `bm25_k1` | 1.5 | Term frequency saturation (standard) |
| `bm25_b` | 0.75 | Length normalization (standard) |

**No Cost**: Runs locally, no API calls

### Hybrid Fusion

| Parameter | Value | What It Means |
|-----------|-------|---------------|
| `vector_weight` | 0.5 | Weight for vector search (50%) |
| `bm25_weight` | 0.5 | Weight for keyword search (50%) |
| `rrf_k` | 60 | RRF fusion constant (standard) |

**Equal weights** because both are important for this use case.

### Reranking

| Parameter | Value | What It Means |
|-----------|-------|---------------|
| `rerank_model` | rerank-english-v3.0 | Cohere's reranking model |
| `rerank_top_k` | 10 | Keep top 10 after reranking |

**Cost**: ~$0.0015 per query (3 reranking calls)

### Answer Generation

| Parameter | Value | What It Means |
|-----------|-------|---------------|
| `llm_model` | llama-3.3-70b-versatile | Groq's Llama 3.3 70B model |
| `temperature` | 0.3 | Low = more focused, high = more creative |
| `max_tokens` | 2000 | Maximum answer length |

**Cost**: FREE (Groq free tier: 100K tokens/day â‰ˆ 14 queries)

### Context Window

| Parameter | Value | What It Means |
|-----------|-------|---------------|
| `final_context_chunks` | 20 | How many chunks go to LLM |
| `max_context_tokens` | 8000 | Maximum context size for LLM |

**Why 20 chunks**: Balance between comprehensive context and token limits.

---

## Technologies Used

### AI & Machine Learning
- **OpenAI API**: Text embeddings (semantic understanding)
- **Groq API**: LLM inference (Llama 3.3 70B for generation)
- **Cohere API**: Semantic reranking
- **Docling**: PDF processing and structure extraction
- **Sentence Transformers**: Text processing utilities

### Databases & Search
- **Pinecone**: Vector database (cloud-hosted)
- **Rank-BM25**: Keyword search (local)
- **Reciprocal Rank Fusion**: Search result fusion

### Web Framework
- **Streamlit**: Web interface (Python-based)

### Python Libraries
- **LangChain**: LLM framework utilities
- **Pydantic**: Configuration management
- **NumPy/SciPy**: Mathematical operations

---

## Performance & Costs

### Current Performance (Measured on 30 Test Queries)

| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| **Search Quality** | | | |
| Precision@10 | 0.567 | >0.70 | âš ï¸ Needs improvement |
| Recall@10 | 0.551 | >0.60 | âš ï¸ Needs improvement |
| Diversity | 1.000 | >0.70 | âœ… Perfect |
| **Answer Quality** | | | |
| Overall Score | 0.916 | >0.75 | âœ… Excellent |
| Completeness | 1.000 | >0.80 | âœ… Perfect |
| Word Count | 484 words | 400-600 | âœ… Ideal |
| **Performance** | | | |
| Avg Time per Query | 27.4s | <15s | âš ï¸ Needs optimization |
| Success Rate | 100% | 100% | âœ… Perfect |

### Cost Breakdown (Per Query)

| Service | Cost | Purpose |
|---------|------|---------|
| OpenAI Embeddings | $0.0005 | 3 sub-questions Ã— 1 embedding each |
| Cohere Reranking | $0.0015 | 3 sub-questions Ã— 1 reranking each |
| Groq LLM | $0 (FREE) | Answer generation |
| **Total** | **~$0.002** | **Per query** |

**Daily Costs** (at 50 queries/day): ~$0.10/day = ~$3/month

**Note**: Groq free tier allows ~14 queries/day. For production, upgrade to paid tier.

---

## Common Questions

### Q: Can I change the chunk size?

**A**: Yes, in `config/settings.py`:
```python
chunk_size: int = 1000  # Change this
chunk_overlap: int = 200  # And this
```

**But**: You'll need to re-process the entire document:
```bash
python -m src.ingestion.docling_processor
python -m src.ingestion.hierarchical_chunker
python -m src.database.run_phase5  # Re-create indexes
```

**Takes**: ~1-2 hours total

### Q: Can I use a different LLM?

**A**: Yes! Change in `config/settings.py`:
```python
llm_provider: str = "groq"  # or "openai", "anthropic", etc.
llm_model: str = "llama-3.3-70b-versatile"  # Change this
```

Supported: Groq (Llama), OpenAI (GPT), Anthropic (Claude)

### Q: Why is it slow (27 seconds per query)?

**A**: Current bottlenecks:
1. **Sequential sub-question retrieval** (10-12s) - Can be parallelized
2. **Cohere reranking API calls** (3-4s) - Network latency
3. **LLM generation** (3-4s) - Model inference time

**Planned optimizations**: Caching, parallelization, local reranking

### Q: Can I add more documents?

**A**: Yes, but requires code changes:
1. Process new PDF with Docling
2. Chunk with hierarchical chunker
3. Generate embeddings
4. Upload to Pinecone (append to existing index)
5. Update BM25 index

**Not yet supported**: Automatic multi-document ingestion (planned for future).

### Q: How do I improve search quality?

**A**: Several approaches:
1. **Increase `vector_top_k` and `bm25_top_k`** to 50 (from 30)
2. **Fine-tune embedding model** on Watermelon-specific data
3. **Adjust fusion weights** based on your use case
4. **Enable query expansion** (add synonyms, related terms)
5. **Use cross-encoder reranking** instead of Cohere

See `CLAUDE.md` â†’ Upgrade Recommendations section.

### Q: What are the API rate limits?

| Service | Free Tier Limit | What Happens When Exceeded |
|---------|----------------|----------------------------|
| OpenAI | 200K tokens/min | 429 error, wait 1 minute |
| Cohere | 1000 requests/month | 429 error, upgrade required |
| Groq | 100K tokens/day | 429 error, wait until daily reset |
| Pinecone | 100K vectors, 1 index | Cannot add more, upgrade required |

**For production**: Upgrade all services to paid tiers.

### Q: Can I run this offline?

**A**: Partially:
- âœ… **BM25 search**: Fully offline (local index)
- âŒ **Vector search**: Requires Pinecone API (cloud)
- âŒ **Embeddings**: Requires OpenAI API
- âŒ **Reranking**: Requires Cohere API
- âŒ **LLM generation**: Requires Groq API

**For fully offline**: Use local models (Ollama, FAISS, etc.) - requires code changes.

---

## Quick Start Commands

### 1. First Time Setup
```bash
# Install dependencies
pip install -r requirements.txt

# Set up API keys
cp .env.example .env
nano .env  # Add your API keys
```

### 2. Run the Web Interface
```bash
streamlit run app.py
```

Then open http://localhost:8501 in your browser.

### 3. Test a Query Programmatically
```python
from src.generation.end_to_end_pipeline import EndToEndPipeline

pipeline = EndToEndPipeline()
result = pipeline.process_query("How do I set up MS Teams integration?")

print(result.answer.answer)
print(f"Quality score: {result.validation.overall_score}")
```

### 4. Run Evaluation
```bash
# Test on first 5 queries
python -m src.evaluation.comprehensive_evaluation
# Enter: 5

# Test on all 30 queries (watch out for rate limits!)
python -m src.evaluation.comprehensive_evaluation
# Enter: all
```

### 5. Re-process Documentation (if PDF changes)
```bash
# Step 1: Extract from PDF
python -m src.ingestion.docling_processor

# Step 2: Create chunks
python -m src.ingestion.hierarchical_chunker

# Step 3: Create search indexes
python -m src.database.run_phase5
```

---

## Troubleshooting

### Error: "ModuleNotFoundError: No module named 'src'"

**Solution**: Use `python -m` syntax:
```bash
python -m src.module.name  # âœ… Correct
python src/module/name.py  # âŒ Wrong
```

### Error: "Rate limit reached for model llama-3.3-70b-versatile"

**Solution**: Groq free tier limit reached (100K tokens/day â‰ˆ 14 queries)
- Wait until daily reset (midnight UTC)
- Spread testing across multiple days
- Upgrade to Groq Dev Tier for higher limits

### Error: "Pinecone API key not found"

**Solution**: Add API keys to `.env`:
```bash
PINECONE_API_KEY=your_key_here
OPENAI_API_KEY=your_key_here
COHERE_API_KEY=your_key_here
GROQ_API_KEY=your_key_here
```

### Error: "No content found for chunk_id: ..."

**Solution**: This was a known bug (now fixed). If you see this:
1. Check that `cache/hierarchical_embeddings.pkl` exists
2. Ensure `hybrid_search.py` loads content mapping correctly
3. See `MS_TEAMS_INTEGRATION_FIX.md` for details

### Streamlit shows old/cached results

**Solution**: Clear Streamlit cache:
```bash
streamlit cache clear
streamlit run app.py
```

---

## Next Steps

### For Developers
1. Read `CLAUDE.md` for development rules and patterns
2. Read `README.md` for project architecture
3. Explore `src/` modules to understand implementation
4. Check `MS_TEAMS_INTEGRATION_FIX.md` for critical bug fix details

### For Users
1. Run `streamlit run app.py` to start the web interface
2. Try example queries to see how it works
3. Adjust settings in `config/settings.py` if needed

### For Researchers
1. Check `tests/results/comprehensive_evaluation.json` for metrics
2. Run your own evaluation with custom queries
3. See improvement recommendations in `CLAUDE.md`

---

## Important Files to Read

| File | When to Read It |
|------|----------------|
| `README.md` | Understanding project goals and architecture |
| `GETTING_STARTED.md` | **This file** - First time setup |
| `CLAUDE.md` | Development rules, settings, troubleshooting |
| `MS_TEAMS_INTEGRATION_FIX.md` | Understanding critical Pinecone limitation |
| `QUICK_FIX_REFERENCE.md` | Quick lookup for MS Teams fix |
| `DOCUMENTATION_INDEX.md` | Navigating all documentation |

---

## Support

**Questions about the code?**
1. Check `CLAUDE.md` â†’ Common Patterns section
2. Check `CLAUDE.md` â†’ Troubleshooting section
3. Search this file (GETTING_STARTED.md) for your question

**Questions about the MS Teams fix?**
1. Read `QUICK_FIX_REFERENCE.md` (3 min read)
2. Read `MS_TEAMS_INTEGRATION_FIX.md` (full details)

**Want to improve the system?**
1. Check `CLAUDE.md` â†’ Upgrade Recommendations
2. Review evaluation results in `tests/results/`
3. Read performance metrics in this file

---

**Last Updated**: November 2, 2025
**Status**: âœ… System fully operational
**Version**: 1.0
